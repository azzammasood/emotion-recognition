# Emotion Recognition through Facial Expressions 

Description:

This project focuses on emotion recognition through facial expressions using the FER2013 dataset. We propose a novel deep learning architecture called ResDropNet, which incorporates dropout layers within residual blocks in a ResNet. The ResNet architecture has been shown to be very effective for image classification tasks, and our approach of incorporating dropout layers into residual blocks can help to further enhance the performance of these models.

The FER2013 dataset contains over 35,000 images of facial expressions, labeled with one of seven emotions: anger, disgust, fear, happiness, sadness, surprise, and neutral. We trained our ResDropNet architecture on this dataset and achieved an accuracy rate of 70%, demonstrating the effectiveness of our approach for emotion recognition through facial expressions.

Outcome:

Our project's outcome is significant in that it demonstrates the potential of using deep learning models for emotion recognition through facial expressions. Emotion recognition is a challenging problem, as emotions are complex and difficult to quantify. However, our approach using ResDropNet shows that deep learning models can be effective tools for analyzing and classifying emotions from facial expressions.

Moreover, our use of dropout layers within residual blocks in a ResNet is particularly noteworthy. Residual networks have been shown to be very effective for image classification tasks, and our approach of incorporating dropout layers into residual blocks could help to further enhance the performance of these models.

Overall, our project is a valuable contribution to the field of emotion recognition through facial expressions. Our innovative approach using ResDropNet has shown that deep learning models can be effective tools for analyzing and classifying emotions from facial expressions, and our results demonstrate the potential of using these models in real-world applications. We believe that our project can serve as a starting point for further research in this area and can be used as a benchmark for future studies.
